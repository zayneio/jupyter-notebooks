{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.PETS)/'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an is_cat method, which simply checks if the file name matches a naming convention\n",
    "# that dictates if the data in the training set is a cat or a dog.\n",
    "#\n",
    "# dog images start with lowercase, cat images start with uppercase.\n",
    "# example: great_pyranees_173.jpg = dog\n",
    "#\n",
    "def is_cat(x): return x[0].isupper()\n",
    "\n",
    "# from_name_func -> this indicates the filenames can be extracted using a function\n",
    "# applied to the filename.\n",
    "#\n",
    "# valid_pct=0.2 is setting the percentage of our training data that should be set aside \n",
    "# and then used separately as the validation set. In this case, 20%. The data pulled out is \n",
    "# selected randomly.\n",
    "# \n",
    "# seed=42 sets the random seed ro the same value every time we run this code, which menas we get the same \n",
    "# validation set every time we run it. This way, if we change our model and retrain it, we know taht\n",
    "# any differences are due to the changes to the model, not due to having a different random valdiation set.\n",
    "#\n",
    "# item_tfms defines the Transforms that we need. \n",
    "# In this case, Resize(224) -> we are resizing every image to be 224 pixels. \n",
    "# This is the standard size for historical reasons (old pretrained models require this size exactly), \n",
    "# but you can pass pretty much anything. If you increase the size, you'll get a model with better results,\n",
    "# but at the price of speed and memory consumption. The opposite is true if you decrease the size.\n",
    "dls = ImageDataLoaders.from_name_func(\n",
    "    path, get_image_files(path), valid_pct=0.2, seed=42,\n",
    "    label_func=is_cat, item_tfms=Resize(224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a convolutional neural net, specifying what architecture to use (i.e. what kind of model to create),\n",
    "# what data we want to train it on, and what metric to use.\n",
    "#\n",
    "# resnet34 -> ResNet; 34 refers to the number of layers in this variant of the architecture.\n",
    "# (other options are 18, 50, 101, and 152).\n",
    "#\n",
    "# Models using architecture with more layers take longer to train, and are more prone to overfitting\n",
    "# (i.e. you can't train them for as many epochs before the accuracy on the validation set starts getting worse).\n",
    "# On the other hand, when using more data, they can be quite a bit more accurate\n",
    "#\n",
    "# metric -> A metric is a function that measures the quality of the model's predictions using the validation set,\n",
    "# and will be printed at the end of each epoch. In this case, we are using error_rate, which is a function provided\n",
    "# by fastai that does just what it says: tells you what percentage of images in the validation set are being\n",
    "# classified incorrectly. Another common metric for classification is accuracy (which is just 1.0 - error_rate).\n",
    "#\n",
    "# The concept of *metric* may remind you of *loss*, but there is an important distinction.\n",
    "# The entire purpose of loss is to define a \"measure of performance\", that the training system can use to \n",
    "# update the weights automatically. In other words, a good choice for loss is a choice that is easy for \n",
    "# stochastic gradient descent to use. But a metric is defined for human consumption, \n",
    "# so a good metric is one that is easy for you to understand.\n",
    "#\n",
    "# pretrained -> an additional, optional parameter cnn_learner takes. defaults to True. This will set the\n",
    "# weights in your model to values that have already been trained by experts to recognize a thousand different\n",
    "# image categories across 1.3 million photos. A model that has weights that have already been trained on another\n",
    "# dataset is called a *pretrained model*. You should nearly always use a pretrained model, because it means your\n",
    "# model, before you've even shown it any of your data, is already very capable.\n",
    "learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
    "\n",
    "# fine_tune -> this tells fastai how to *fit* the model. This is the key to deep learning - \n",
    "# determining how to fit the parameters of a model to get it to solve your problem.\n",
    "#\n",
    "# To fit a model, we have to provide at least one piece of information: how many times to look at each \n",
    "# image (known as number of *epochs*).\n",
    "# The number of epochs you select will largely depend on how much time you have available, and how long \n",
    "# you find it takes in practice to fit your model. If you pick a number that is too small, you can always\n",
    "# train for more epochs later.\n",
    "#\n",
    "# Note: the method used here is fine_tune. fastai also has a *fit* method, which does indeed fit a model.\n",
    "# But in this case, we've started with a pretrained model, and we don't want to throw away all those capabilities\n",
    "# it already has. So in this case we are *fine-tuning*, or adapting a pretrained model for a new dataset.\n",
    "#\n",
    "# When using the fine_tune method, there are a few parameters you can set. In this example, it does 2 things:\n",
    "# 1. Use one *epoch* to fit just those parts of the model necessary to get the new random *head* to work correctly\n",
    "#    with your data set.\n",
    "# 2. Use the number of *epochs* requested when calling the method to fit the entire model, updating the weights \n",
    "#    of the later layers fasater than the earlier layers.\n",
    "#\n",
    "# *head* -> The head of a model is the part that is newly added to be specific to the new dataset.\n",
    "# *epoch* -> An epoch is one complete pass through the dataset.\n",
    "learn.fine_tune(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install ipywidgets\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# widget image uploader. Add a custom image to test with.\n",
    "uploader = widgets.FileUpload()\n",
    "uploader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PILImage mode=RGB size=1500x1200\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is this a cat?: True\n",
      "Probability it's a cat: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# final results\n",
    "img = PILImage.create(uploader.data[0])\n",
    "print(img)\n",
    "\n",
    "is_cat, _, probs = learn.predict(img)\n",
    "print(f\"Is this a cat?: {is_cat}\")\n",
    "print(f\"Probability it's a cat: {probs[1].item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
